nbn-elk-1
ala-install-test-1
ala-install-test-2
ala-install-test-3

[elk_forwarder]
nbn-elk-1
ala-install-test-1
ala-install-test-2
ala-install-test-3

[logstash]
nbn-elk-1

[kibana]
nbn-elk-1

[elastic]
nbn-elk-1

# Use a different group name instead of group1, ... like biocache, solr, cassandra, ... in production
[group1]
ala-install-test-1

[group2]
ala-install-test-2

[group3]
ala-install-test-3

[elastic:vars]
la_hostname="nbn-elk-1"
elasticsearch_node_name="nbn-elk-1"
elasticsearch_cluster_name='nbn-elk'
elasticsearch_node_ip='10.20.20.134'
elasticsearch_discovery_hosts='["nbn-elk-1"]'
elasticsearch_minimum_master_nodes=1
elasticsearch_number_of_nodes=1
elasticsearch_heap_size='2g'
elasticsearch_http_port=9200
# https://www.elastic.co/guide/en/elasticsearch/reference/current/security-basic-setup.html
# Generate with:
# https://www.elastic.co/guide/en/elasticsearch/reference/current/certutil.html
# /usr/share/elasticsearch/bin/elasticsearch-certutil cert --silent --in /usr/share/elasticsearch/instances.yml --out test1.zip --keep-ca-key
# without password in the tests
elasticsearch_security_enabled=False
elasticsearch_security_transport_ssl_enabled=False
elasticsearch_security_http_ssl_enabled=False

[kibana:vars]
kibana_hostname='nbn-elk-1'
#logstash_elasticsearch_url="https://nbn-elk-1"
logstash_elasticsearch_url="http://nbn-elk-1"
elasticsearch_http_port=9200
kibana_security_enabled=False
kibana_security_audit_enabled=False
kibana_elasticsearch_username="kibana_system"
kibana_elasticsearch_password="PUT_SOMETHING_HERE"
# generate with /usr/share/kibana/bin/kibana-encryption-keys generate -i
kibana_xpack_encrypted_saved_objects_encryption_key="f749b938e2a67814d9445aa8f2be313d"
kibana_xpack_security_encryption_key="36e4683e89c303d4e563856e99ad2622"
ssl=True
la_tags=["aws", "elastic", "kibana", "logstash"]
metricbeat_kibana_enabled=True
metricbeat_kibana_monitoring_username=remote_monitoring_user
metricbeat_kibana_monitoring_password=spurningfragrantlyprocessed
metricbeat_enabled=True
metricbeat_elasticsearch_enabled=True

[logstash:vars]
logstash_heap_size='4g'
logstash_queue_type=persisted
logstash_queue_max_bytes=15gb
#logstash_elasticsearch_url="https://nbn-elk-1"
logstash_elasticsearch_url="http://nbn-elk-1"
# Disabled, follow:
# https://www.elastic.co/guide/en/logstash/current/ls-security.html
logstash_auth=False
logstash_elasticsearch_username="logstash_internal"
logstash_elasticsearch_password="PUT_SOMETHING_HERE"
elasticsearch_http_port=9200
# la_tags=["aws", "elastic", "kibana", "logstash"]
packetbeat_enabled=False
# Please change this with other account
maxmind_account_id="292034"
maxmind_license_key="CHANGE_ME"

[elk_forwarder:vars]
metricbeat_kibana_monitoring_username=remote_monitoring_user
metricbeat_kibana_monitoring_password=spurningfragrantlyprocessed
metricbeat_elasticsearch_monitoring_username=remote_monitoring_user
metricbeat_elasticsearch_monitoring_password=spurningfragrantlyprocessed
metricbeat_enabled=True
filebeat_enabled=True
logstash_elasticsearch_url="http://nbn-elk-1"

[elastic:vars]

metricbeat_enabled=True
metricbeat_elasticsearch_enabled=True
# Generate with:
# /usr/share/elasticsearch/bin/elasticsearch-setup-passwords interactive
metricbeat_elasticsearch_monitoring_username=remote_monitoring_user
metricbeat_elasticsearch_monitoring_password=spurningfragrantlyprocessed
metricbeat_system_enabled=False
la_tags=["aws", "elastic", "kibana", "logstash"]

[group1:vars]
# The name of the shipper that publishes the network data.
# It can be used to group all the transactions sent by a single shipper in the web interface.
# something like
#la_hostname='aws_biocache'
la_hostname=ala-install-test-1
la_webserver="nginx"
# Files in /var/log/tomcat* to monit
la_tomcat7_logfiles=False
la_tomcat8_logfiles=["ala-bie", "ala-collectory", "ala-hub", "bie-index", "biocache-service", "regions"]
la_java_logfiles=["atlas/cas/cas.log","atlas/cas/cas_audit.log","atlas/userdetails/userdetails.log","atlas/apikey/apikey.log","atlas/cas-management/cas-management.log"]
la_tags=["aws", "biocache", "hubs", "production"]
metricbeat_system_enabled=True

[group2:vars]
# The name of the shipper that publishes the network data.
# It can be used to group all the transactions sent by a single shipper in the web interface.
la_hostname=ala-install-test-2
la_webserver="nginx"
la_tomcat7_logfiles=False
la_tomcat8_logfiles=["alerts", "logger", "specieslist-webapp"]
la_java_logfiles=["image-service/image-service.log"]
la_tags=["aws", "solr", "alerts", "logger", "production"]
metricbeat_system_enabled=True

[group3:vars]
# The name of the shipper that publishes the network data.
# It can be used to group all the transactions sent by a single shipper in the web interface.
la_hostname=ala-install-test-3
la_webserver="nginx"
la_tomcat7_logfiles=False
la_tomcat8_logfiles=["geonetwork"]
la_java_logfiles=["cassandra/system.log"]
la_tags=["aws", "cassandra", "spatial", "production"]
metricbeat_system_enabled=True

[auditbeat_active:children]
group1
group2
group3

[auditbeat_active:vars]
auditbeat_enabled=True
auditbeat_module_system_socket_enabled=False
auditbeat_logging_level="debug"

[all:vars]
es_major_version="7.x"
# Open source version
#es_major_version="oss-7.x"
oss_version=False

elasticsearch_version=7.10.2
kibana_version=7.10.0
logstash_version=1:7.12.0-1
beats_version=7.12.0

kibana_node_ip='10.20.20.134'
la_logstash_host="nbn-elk-1:5044"
# Expected boolean 'true' or 'false'
logstash_ssl_enabled=false
logstash_elasticsearch_username="logstash_internal"
logstash_elasticsearch_password="PUT_SOMETHING_HERE"

# 0) edit: roles/elk_forwarder/tasks/main.yml
# 1) # elastic with ssl and security false in this inventory
# ansible-playbook -i inventory.ini ./elasticsearch.yml --become
# 1a)  service elasticsearch start
# 2) ansible-playbook -i inventory.ini ./kibana.yml --become
# 2a) ansible-playbook -i inventory.ini ./elk_forwarder.yml --become --limit nbn-elk-1 # start monitoring elk
# 3) adjust ./roles/logstash/files/templates/logstash-solr-template.json
# 3a) ansible-playbook -i inventory.ini ./logstash.yml --become
# 4) /usr/bin/geoipupdate --config-file /etc/GeoIP.conf --database-directory /usr/share/GeoIP
# 5) ansible-playbook -i inventory.ini ./elk_forwarder.yml --become
# 6) Optional: Setup SSL/TLS component by component
# https://www.elastic.co/blog/configuring-ssl-tls-and-https-to-secure-elasticsearch-kibana-beats-and-logstash
# 7) jvm adjusts (`grep -r "when: 0" .` for disabled tasks)
# 8) jenkins curator

# To generate passwords/certs:














# cat /usr/share/elasticsearch/instances.yml
# instances:
#   - name: "nbn-elk-1"
#     ip:
#       - "10.20.20.134"
#     dns:
#       - "kibana-lic.l-a.site"
